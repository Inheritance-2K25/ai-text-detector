{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets accelerate scikit-learn safetensors","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:00.497178Z","iopub.execute_input":"2026-01-20T12:55:00.497556Z","iopub.status.idle":"2026-01-20T12:55:04.128908Z","shell.execute_reply.started":"2026-01-20T12:55:00.497524Z","shell.execute_reply":"2026-01-20T12:55:04.127907Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments\n)\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:04.130451Z","iopub.execute_input":"2026-01-20T12:55:04.130730Z","iopub.status.idle":"2026-01-20T12:55:13.564885Z","shell.execute_reply.started":"2026-01-20T12:55:04.130698Z","shell.execute_reply":"2026-01-20T12:55:13.564283Z"}},"outputs":[{"name":"stderr","text":"2026-01-20 12:55:10.269013: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768913710.292313     411 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768913710.299320     411 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768913710.317003     411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768913710.317027     411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768913710.317029     411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768913710.317031     411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"dataset = load_dataset(\"silentone0725/ai-human-text-detection-v1\")\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:13.565754Z","iopub.execute_input":"2026-01-20T12:55:13.566393Z","iopub.status.idle":"2026-01-20T12:55:14.391279Z","shell.execute_reply.started":"2026-01-20T12:55:13.566354Z","shell.execute_reply":"2026-01-20T12:55:14.390489Z"}},"outputs":[{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\nWARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 36744\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 7874\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 7874\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"label2id = {\"human\": 0, \"ai\": 1}\nid2label = {0: \"human\", 1: \"ai\"}\n\ndef encode_labels(example):\n    example[\"label\"] = label2id[example[\"label\"]]\n    return example\n\ndataset = dataset.map(encode_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:14.393045Z","iopub.execute_input":"2026-01-20T12:55:14.393338Z","iopub.status.idle":"2026-01-20T12:55:16.410536Z","shell.execute_reply.started":"2026-01-20T12:55:14.393313Z","shell.execute_reply":"2026-01-20T12:55:16.409678Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36744 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a14646e49a547d6b2c018308941c328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd9da4fd84d4b428b2754482c4f8059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c8098abfa63476babec2d07c8875aab"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def clean(example):\n    example[\"text\"] = \"\" if example[\"text\"] is None else str(example[\"text\"])\n    return example\n\ndataset = dataset.map(clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:16.411465Z","iopub.execute_input":"2026-01-20T12:55:16.411689Z","iopub.status.idle":"2026-01-20T12:55:18.335782Z","shell.execute_reply.started":"2026-01-20T12:55:16.411667Z","shell.execute_reply":"2026-01-20T12:55:18.335091Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36744 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c79e379cbfa4190abacf56b1828da0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287c3c22765c4d438d64faf0c80b4727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dcc08ac15bf4760bcb28a15e1de6556"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nMODEL_NAME = \"microsoft/deberta-v3-small\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=256\n    )\n\ntokenized = dataset.map(\n    tokenize,\n    batched=True,\n    remove_columns=[\"text\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:18.337003Z","iopub.execute_input":"2026-01-20T12:55:18.337295Z","iopub.status.idle":"2026-01-20T12:55:36.699568Z","shell.execute_reply.started":"2026-01-20T12:55:18.337268Z","shell.execute_reply":"2026-01-20T12:55:36.698706Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36744 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e92435a9c3446678c89ce7118bf9b52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"853d992de5524e598a658776e3e54be3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820de141d05f4d9394fd76bdc9b107c1"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenized = tokenized.rename_column(\"label\", \"labels\")\ntokenized.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:36.700654Z","iopub.execute_input":"2026-01-20T12:55:36.701013Z","iopub.status.idle":"2026-01-20T12:55:36.715414Z","shell.execute_reply.started":"2026-01-20T12:55:36.700986Z","shell.execute_reply":"2026-01-20T12:55:36.714374Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n    label2id=label2id,\n    id2label=id2label\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:36.716552Z","iopub.execute_input":"2026-01-20T12:55:36.716834Z","iopub.status.idle":"2026-01-20T12:55:39.028590Z","shell.execute_reply.started":"2026-01-20T12:55:36.716806Z","shell.execute_reply":"2026-01-20T12:55:39.027981Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c5a85efbd840089e23c67e007d716a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,   # DeBERTa is heavy\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    report_to=\"none\",\n    fp16=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized[\"train\"],\n    eval_dataset=tokenized[\"validation\"],\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:39.031388Z","iopub.execute_input":"2026-01-20T12:55:39.032024Z","iopub.status.idle":"2026-01-20T12:55:39.324854Z","shell.execute_reply.started":"2026-01-20T12:55:39.031997Z","shell.execute_reply":"2026-01-20T12:55:39.324241Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_411/1635414317.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ae79dc1cff344258de735508e1f7357"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T12:55:39.326486Z","iopub.execute_input":"2026-01-20T12:55:39.326697Z","iopub.status.idle":"2026-01-20T13:39:36.259951Z","shell.execute_reply.started":"2026-01-20T12:55:39.326677Z","shell.execute_reply":"2026-01-20T13:39:36.259143Z"}},"outputs":[{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27558' max='27558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27558/27558 43:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.013100</td>\n      <td>0.036565</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.011454</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.004200</td>\n      <td>0.027073</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27558, training_loss=0.01644947550833741, metrics={'train_runtime': 2636.5827, 'train_samples_per_second': 41.809, 'train_steps_per_second': 10.452, 'total_flos': 7301333214240768.0, 'train_loss': 0.01644947550833741, 'epoch': 3.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\npredictions = trainer.predict(tokenized[\"test\"])\ny_pred = np.argmax(predictions.predictions, axis=1)\ny_true = tokenized[\"test\"][\"labels\"]\n\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=[\"human\", \"ai\"]))\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T13:41:08.132378Z","iopub.execute_input":"2026-01-20T13:41:08.133028Z","iopub.status.idle":"2026-01-20T13:42:04.115313Z","shell.execute_reply.started":"2026-01-20T13:41:08.132988Z","shell.execute_reply":"2026-01-20T13:42:04.114667Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n       human       1.00      0.99      1.00      3937\n          ai       0.99      1.00      1.00      3937\n\n    accuracy                           1.00      7874\n   macro avg       1.00      1.00      1.00      7874\nweighted avg       1.00      1.00      1.00      7874\n\nConfusion Matrix:\n[[3903   34]\n [   1 3936]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"MODEL_SAVE_PATH = \"./ai_text_detector_small\"\nmodel.save_pretrained(MODEL_SAVE_PATH)\ntokenizer.save_pretrained(MODEL_SAVE_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T13:43:56.845683Z","iopub.execute_input":"2026-01-20T13:43:56.846560Z","iopub.status.idle":"2026-01-20T13:43:58.021809Z","shell.execute_reply.started":"2026-01-20T13:43:56.846527Z","shell.execute_reply":"2026-01-20T13:43:58.020991Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./ai_text_detector_small/tokenizer_config.json',\n './ai_text_detector_small/special_tokens_map.json',\n './ai_text_detector_small/spm.model',\n './ai_text_detector_small/added_tokens.json',\n './ai_text_detector_small/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import torch\n\n# detect device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)  # move model to GPU if available\n\ndef predict_text(text):\n    # tokenize\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=256\n    )\n\n    # move inputs to same device as model\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    # forward pass\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**inputs)\n        probs = torch.softmax(outputs.logits, dim=1)\n\n    ai_prob = probs[0][1].item()\n    human_prob = probs[0][0].item()\n    label = \"AI-generated\" if ai_prob > human_prob else \"Human-written\"\n\n    return {\"label\": label, \"ai_probability\": round(ai_prob, 3), \"human_probability\": round(human_prob, 3)}\n\n# test\nsample = \"\"\nprint(predict_text(sample))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T13:51:23.094957Z","iopub.execute_input":"2026-01-20T13:51:23.095653Z","iopub.status.idle":"2026-01-20T13:51:23.409403Z","shell.execute_reply.started":"2026-01-20T13:51:23.095621Z","shell.execute_reply":"2026-01-20T13:51:23.408625Z"}},"outputs":[{"name":"stdout","text":"{'label': 'Human-written', 'ai_probability': 0.0, 'human_probability': 1.0}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"ai_text_detector_small\", 'zip', \"ai_text_detector_small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T13:52:55.215993Z","iopub.execute_input":"2026-01-20T13:52:55.216601Z","iopub.status.idle":"2026-01-20T13:53:24.728799Z","shell.execute_reply.started":"2026-01-20T13:52:55.216568Z","shell.execute_reply":"2026-01-20T13:53:24.728095Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/ai_text_detector_small.zip'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}